{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec99852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Simulate reading the CSV data from the provided strings\n",
    "# In a real pipeline, you would replace io.StringIO(csv_data) with a file path:\n",
    "# pd.read_csv('s3://your-bucket/employee_master.csv') or pd.read_csv('employee_master.csv')\n",
    "\n",
    "# --- 1. Employee Master Data ---\n",
    "master_csv = \"\"\"Employee_ID,Hire_Date,Job_Role,Job_Level,Monthly_Base_Salary,Termination_Date\n",
    "E001,2021-03-01,Sales Executive,3,5500,\n",
    "E002,2017-06-01,Senior Dev,4,11200,\n",
    "E003,2023-11-01,Marketing Analyst,2,4100,\n",
    "E004,2018-01-15,HR Generalist,3,6000,2025-08-01\n",
    "E005,2024-09-15,Junior Dev,2,8500,\n",
    "E006,2022-04-10,Financial Manager,4,9800,\n",
    "E007,2023-07-01,Sales Lead,3,7200,2025-09-30\n",
    "\"\"\"\n",
    "df_master = pd.read_csv(io.StringIO(master_csv), parse_dates=['Hire_Date', 'Termination_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb332597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Promotion History ---\n",
    "promo_csv = \"\"\"Employee_ID,Promotion_Date,New_Job_Level\n",
    "E001,2022-01-01,3\n",
    "E002,2024-07-01,4\n",
    "E003,2024-03-01,2\n",
    "E004,2020-07-01,3\n",
    "E006,2022-04-10,4\n",
    "E006,2024-01-01,4\n",
    "E007,2024-01-01,3\n",
    "\"\"\"\n",
    "df_promo = pd.read_csv(io.StringIO(promo_csv), parse_dates=['Promotion_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ccc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Timesheet Data ---\n",
    "ot_csv = \"\"\"Employee_ID,Total_OT_Hours_90_Days\n",
    "E001,135\n",
    "E002,45\n",
    "E003,0\n",
    "E004,180\n",
    "E005,18\n",
    "E006,108\n",
    "E007,270\n",
    "\"\"\"\n",
    "df_ot = pd.read_csv(io.StringIO(ot_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117b9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All four DataFrames are loaded and ready for transformation.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Performance Data ---\n",
    "perf_csv = \"\"\"Employee_ID,Review_Date,Rating_Score\n",
    "E001,2025-01-01,3.5\n",
    "E002,2025-03-01,4.5\n",
    "E003,2024-12-01,3.0\n",
    "E004,2024-08-01,2.5\n",
    "E005,2024-12-01,3.8\n",
    "E006,2025-01-01,4.0\n",
    "E007,2024-12-01,3.5\n",
    "\"\"\"\n",
    "df_perf = pd.read_csv(io.StringIO(perf_csv), parse_dates=['Review_Date'])\n",
    "\n",
    "print(\"All four DataFrames are loaded and ready for transformation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79dc8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DataFrame load to PostgreSQL...\n",
      "   ✅ Loaded 7 rows into table: 'employee_master'\n",
      "   ✅ Loaded 7 rows into table: 'promotion_history'\n",
      "   ✅ Loaded 7 rows into table: 'timesheet_data'\n",
      "   ✅ Loaded 7 rows into table: 'performance_data'\n",
      "\n",
      "All four source tables successfully transferred to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "\n",
    "# --- A. Database Credentials ---\n",
    "# IMPORTANT: Replace these with your actual credentials\n",
    "DB_USER = \"postgres\"        \n",
    "DB_PASSWORD = \"postgres\"    \n",
    "DB_HOST = \"localhost\"            \n",
    "DB_PORT = \"5433\"                 \n",
    "DB_NAME = \"hr_data\"             \n",
    "\n",
    "# SQLAlchemy connection string\n",
    "DB_STRING = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# --- C. Define Loading Instructions ---\n",
    "# Pair the loaded DataFrames with their intended PostgreSQL table names\n",
    "dataframes_to_load = [\n",
    "    {\"df\": df_master, \"table_name\": \"employee_master\"},\n",
    "    {\"df\": df_promo, \"table_name\": \"promotion_history\"},\n",
    "    {\"df\": df_ot, \"table_name\": \"timesheet_data\"},\n",
    "    {\"df\": df_perf, \"table_name\": \"performance_data\"}\n",
    "]\n",
    "\n",
    "# --- D. Execution Loop ---\n",
    "try:\n",
    "    # Create the connection engine\n",
    "    engine = create_engine(DB_STRING)\n",
    "    \n",
    "    print(\"Starting DataFrame load to PostgreSQL...\")\n",
    "\n",
    "    for item in dataframes_to_load:\n",
    "        df = item['df']\n",
    "        table_name = item['table_name']\n",
    "\n",
    "        # Use .to_sql() to write the DataFrame directly to the database\n",
    "        df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists='replace', # Overwrite the table if it already exists\n",
    "            index=False          # Do not write the DataFrame index as a column\n",
    "        )\n",
    "        print(f\"   ✅ Loaded {len(df)} rows into table: '{table_name}'\")\n",
    "\n",
    "    print(\"\\nAll four source tables successfully transferred to PostgreSQL.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during database load: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the database connection is closed\n",
    "    if 'engine' in locals() and engine:\n",
    "        engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
